{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Аналіз тонування тексту\n",
    "Для аналізу тонування тексту певного твердження із соціальної мережі Twitter буде використовуватися логістична регресія. Дано твердження, потрібно вирішити чи має воно позитивне тонування чи негативне. Для цього потрібно зробити наступні кроки:  \n",
    "1.\tІмпорт функцій і зчитування даних\n",
    "2.\tПоділ на тренуючий та тестовий набори даних\n",
    "3.\tВилучення ознак\n",
    "4.\tПобудова моделі передбачення\n",
    "5.\tОцінка моделі на тестовому наборі даних\n",
    "6.\tАналіз помилок\n",
    "7.\tПрогнозування власного твердження\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Імпорт функцій і зчитування даних\n",
    "\n",
    "### Зчитування набору даних\n",
    "\n",
    "\n",
    "Оригінальна документація набору вхідних приведена у [документація для набору даних із мережі Twitter](http://www.nltk.org/howto/twitter.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package twitter_samples to\n",
      "[nltk_data]     C:\\Users\\Андрей\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package twitter_samples is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Андрей\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run this cell to import nltk\n",
    "import nltk\n",
    "from os import getcwd\n",
    "\n",
    "nltk.download('twitter_samples')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Імпорт функцій\n",
    "\n",
    "#### NaturalLanguageProcessing-модуль:\n",
    "* process_tweet: повертає попередньо оброблене твердження, а саме видаляє усі посилання, хештег-символи, токенізує рядок, приводить слова до нижнього регістру, видаляє стоп слова та пунктуацію, приводить слова до кореня.\n",
    "* build_freqs: повертає словник, що має (слово, тонація) в якості ключа і частоту використання слова до відповідної тональності в якості значення.\n",
    "\n",
    "\n",
    "#### MachineLearning-модуль\n",
    "* sigmoid: функція сигмоїди. Вихідним значенням є результат сигмоїди.\n",
    "* gradientDescent: функція, що представляє собою алгоритм градієнтного спуску. У результаті виконання повертає значення функції вартості J та оновлений вектор вагових коефіцієнтів theta.\n",
    "* extract_features: функція вилучення ознак у твердженні, що приймає одне твердження та словник частотності слів.\n",
    "* predict_tweet: функція для прогнозування чи твердження позитивне чи негативне. Повертає прогнозоване значення за допомогою налаштованої моделі класифікації.\n",
    "* test_logistic_regression: функція для перевірки точності побудованої моделі. Повертає значення точності прогнозування міток для тестового набору даних"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "filePath = f\"{getcwd()}/../tmp2/\"\n",
    "nltk.data.path.append(filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import twitter_samples \n",
    "\n",
    "from NaturalLanguageProcessing import process_tweet, build_freqs\n",
    "from MachineLearning import sigmoid, gradientDescent, extract_features, predict_tweet, test_logistic_regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Поділ на тренуючий та тестовий набори даних\n",
    "Набір даних `twitter_samples` має підмножину з 5000 позитивних тверджень і 5000 негативних. Повна кількість записів у наборі даних складає 10000 тверджень.\n",
    "\n",
    "Розбиття даних на тренуючий та тестовий набори відбуватися у наступних співвідношеннях: \n",
    "* 20% буде у тестовому наборі;\n",
    "* 80% у тренуючому наборі."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "all_negative_tweets = twitter_samples.strings('negative_tweets.json')\n",
    "\n",
    "train_pos = all_positive_tweets[:4000]\n",
    "train_neg = all_negative_tweets[:4000]\n",
    "\n",
    "test_pos = all_positive_tweets[4000:]\n",
    "test_neg = all_negative_tweets[4000:]\n",
    "\n",
    "train_x = train_pos + train_neg \n",
    "test_x = test_pos + test_neg\n",
    "\n",
    "train_y = np.append(np.ones((len(train_pos), 1)), np.zeros((len(train_neg), 1)), axis=0)\n",
    "test_y = np.append(np.ones((len(test_pos), 1)), np.zeros((len(test_neg), 1)), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вивід кількості даних у тренуючому та тестовому наборах відповідно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Розмірність тренуючого набору даних = (8000, 1)\n",
      "Розмірність тестуючого набору даних = (2000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Розмірність тренуючого набору даних = \" + str(train_y.shape))\n",
    "print(\"Розмірність тестуючого набору даних = \" + str(test_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Приклад даних"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Твердження з позитивним змістом: \n",
      "@VJAdeel \n",
      "Weltum he teh dety :p Huh =D\n",
      "\n",
      "Твердження з негативним змістом: \n",
      "WHY MUST THE VIDEO STOP THO :(\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "print('Твердження з позитивним змістом: \\n' + train_pos[random.randint(0, 4000)])\n",
    "print('\\nТвердження з негативним змістом: \\n' + train_neg[random.randint(0, 4000)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Вилучення ознак\n",
    "\n",
    "Для кожного твердження у наборі даних потрібно дістати дві ознаки, а саме:\n",
    "* Перша ознака - це кількість позитивних слів у тверджені.\n",
    "* Друга ознака - це кількість негативних слів у тверджені. \n",
    "\n",
    "\n",
    "### Етап попередньої обробки даних\n",
    "Етап попередньої обробки даних відбувається разом з етапом вилучення ознак.\n",
    "Функція для попередньої обробки даних `process_tweet`, що використовується у функції вилучення ознак `extract_features` містить усі етапи обробки даних:\n",
    "* Токенізація рядка.\n",
    "* Приведення тексту до нижнього регістру.\n",
    "* Видалення стоп слів і пунктуації.\n",
    "* Приведення слів до їх кореня.\n",
    "\n",
    "\n",
    "### Приклад використання функції `process_tweet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Твердження у соціальній мережі твітер: \n",
      " @chingyapp hmmm, i think night better :)\n",
      "\n",
      "Оброблений вид цього твердження: \n",
      " ['hmmm', 'think', 'night', 'better', ':)']\n"
     ]
    }
   ],
   "source": [
    "process_tweet_example = train_x[random.randint(0,8000)]\n",
    "print('Твердження у соціальній мережі твітер: \\n', process_tweet_example)\n",
    "print('\\nОброблений вид цього твердження: \\n', process_tweet(process_tweet_example))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Приклад використання функції `extract_features`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Приклад для твердження, що має слова наявні у словнику:\n",
      "\n",
      "Твердження: @s0ulfl0wr When's your birthday ? :(\n",
      "[[1.000e+00 5.400e+01 3.692e+03]]\n",
      "\n",
      "\n",
      "Приклад для твердження, яке не має слів наявних у словнику:\n",
      "\n",
      "[[1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print('Приклад для твердження, що має слова наявні у словнику:\\n')\n",
    "extract_features_example = train_x[random.randint(0,8000)]\n",
    "print('Твердження: ' + str(extract_features_example))\n",
    "tmp1 = extract_features(extract_features_example, freqs)\n",
    "print(tmp1)\n",
    "\n",
    "print('\\n\\nПриклад для твердження, яке не має слів наявних у словнику:\\n')\n",
    "tmp1 = extract_features('Baaang HEEEY', freqs)\n",
    "print(tmp1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вилучення ознак\n",
    "#### Створення словника частотності\n",
    "Створення словника частот наявних слів відбувається за допомогою імпортованої функції `build_freqs` .  \n",
    "Ключом у такому словнику є пара (слово, мітка), наприклад (\"дослідження\", 1) або (\"дослідження\", 0). Значення, що зберігається для кожного ключа є кількість разів, коли слово \"дослідження\" асоціювалось з позитивної міткою, або з негативною міткою відповідно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тип змінної, що представляє словник: <class 'dict'>\n",
      "Кількість слів у словнику: 11436\n"
     ]
    }
   ],
   "source": [
    "freqs = build_freqs(train_x, train_y)\n",
    "print(\"Тип змінної, що представляє словник: \" + str(type(freqs)))\n",
    "print(\"Кількість слів у словнику: \" + str(len(freqs.keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Підрахунок частот\n",
    "Для кожного слова у словника підраховується кількість вживання слова як у твердженнях з позитивною тональністю, так і з негативною. Таким чином, ми отримуємо дві характеристики."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect the features 'x' and stack them into a matrix 'X'\n",
    "X = np.zeros((len(train_x), 3))\n",
    "for i in range(len(train_x)):\n",
    "    X[i, :]= extract_features(train_x[i], freqs)\n",
    "    \n",
    "\n",
    "# training labels corresponding to X\n",
    "Y = train_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Побудова моделі передбачення \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Щоб натренувати модель потрібно визвати функцію градієнтного спуску `gradientDescent`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Функція вартості після тренування = 0.22522315.\n",
      "Результуючий вектор вагових коефіцієнтів: [6e-08, 0.00053818, -0.0005583]\n"
     ]
    }
   ],
   "source": [
    "J, theta = gradientDescent(X, Y, np.zeros((3, 1)), 1e-9, 1500)\n",
    "print(f\"Функція вартості після тренування = {J:.8f}.\")\n",
    "print(f\"Результуючий вектор вагових коефіцієнтів: {[round(t, 8) for t in np.squeeze(theta)]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Оцінка моделі на тестовому наборі даних\n",
    "\n",
    "Після тренування моделі, перевіримо як наша модель може бути застосована на дійсних даних з якими модель ще не працювала.\n",
    "Для цього викоростаємо функцію `predict_tweet`, яка за допомогою побудованої моделі спрогнозує чи твердження позитивне або негативне\n",
    "\n",
    "### Приклад використання функції `predict_tweet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am happy -> 0.519275\n",
      "I am bad -> 0.494347\n",
      "this movie should have been great. -> 0.515979\n",
      "great -> 0.516065\n",
      "great great -> 0.532096\n",
      "great great great -> 0.548062\n",
      "great great great great -> 0.563929\n",
      "I am learning :) -> 0.831103\n",
      ":) -> 0.830885\n",
      ":( -> 0.113930\n"
     ]
    }
   ],
   "source": [
    "example_predict_tweet = ['I am happy',\n",
    "                         'I am bad',\n",
    "                         'this movie should have been great.',\n",
    "                         'great',\n",
    "                         'great great',\n",
    "                         'great great great',\n",
    "                         'great great great great',\n",
    "                         'I am learning :)',\n",
    "                        ':)',\n",
    "                        ':(']\n",
    "\n",
    "for tweet in example_predict_tweet:\n",
    "    print( '%s -> %f' % (tweet, predict_tweet(tweet, freqs, theta)))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оцінка моделі на тестовому наборі даних\n",
    "\n",
    "Дано тестовий набір даних і вагові коефіцієнти побудованої моделі. Обчислимо точність побудованої логістичної регресійної моделі за допомогою функції `test_logistic_regression` , яка містить функцію для прогнозування кожного твердження у наборі даних - `predict_tweet`.\n",
    "* Якщо прогнозування більше > 0.5, то встановити класифікацію моделі рівній 1, інакше встановити класифікацію моделі рівній 0.\n",
    "* Прогнозування точне коли пронозована мітка відповідає актуальній. Потрібно підсумувати кількість правильних відповідностей і поділити на загальну кількість міток у тестовому наборі даних.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точність логістичної регресійної моделі = 0.9950\n"
     ]
    }
   ],
   "source": [
    "tmp_accuracy = test_logistic_regression(test_x, test_y, freqs, theta)\n",
    "print(f\"Точність логістичної регресійної моделі = {tmp_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Аналіз помилок\n",
    "\n",
    "У цій частині буде видно деякі твердження, що були невірно класифіковані."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Твердження: @MarkBreech Not sure it would be good thing 4 my bottom daring 2 say 2 Miss B but Im gonna be so stubborn on mouth soaping ! #NotHavingit :p\n",
      "Оброблене твердження: ['sure', 'would', 'good', 'thing', '4', 'bottom', 'dare', '2', 'say', '2', 'miss', 'b', 'im', 'gonna', 'stubborn', 'mouth', 'soap', 'nothavingit', ':p']\n",
      "1\t0.48901497\tb'sure would good thing 4 bottom dare 2 say 2 miss b im gonna stubborn mouth soap nothavingit :p'\n",
      "Твердження: I'm playing Brain Dots : ) #BrainDots\n",
      "http://t.co/UGQzOx0huu\n",
      "Оброблене твердження: [\"i'm\", 'play', 'brain', 'dot', 'braindot']\n",
      "1\t0.48418949\tb\"i'm play brain dot braindot\"\n",
      "Твердження: I'm playing Brain Dots : ) #BrainDots http://t.co/aOKldo3GMj http://t.co/xWCM9qyRG5\n",
      "Оброблене твердження: [\"i'm\", 'play', 'brain', 'dot', 'braindot']\n",
      "1\t0.48418949\tb\"i'm play brain dot braindot\"\n",
      "Твердження: I'm playing Brain Dots : ) #BrainDots http://t.co/R2JBO8iNww http://t.co/ow5BBwdEMY\n",
      "Оброблене твердження: [\"i'm\", 'play', 'brain', 'dot', 'braindot']\n",
      "1\t0.48418949\tb\"i'm play brain dot braindot\"\n",
      "Твердження: off to the park to get some sunlight : )\n",
      "Оброблене твердження: ['park', 'get', 'sunlight']\n",
      "1\t0.49636374\tb'park get sunlight'\n",
      "Твердження: @msarosh Uff Itna Miss karhy thy ap :p\n",
      "Оброблене твердження: ['uff', 'itna', 'miss', 'karhi', 'thi', 'ap', ':p']\n",
      "1\t0.48237069\tb'uff itna miss karhi thi ap :p'\n",
      "Твердження: @phenomyoutube u probs had more fun with david than me : (\n",
      "Оброблене твердження: ['u', 'prob', 'fun', 'david']\n",
      "0\t0.50988239\tb'u prob fun david'\n",
      "Твердження: pats jay : (\n",
      "Оброблене твердження: ['pat', 'jay']\n",
      "0\t0.50040365\tb'pat jay'\n",
      "Твердження: my beloved grandmother : ( https://t.co/wt4oXq5xCf\n",
      "Оброблене твердження: ['belov', 'grandmoth']\n",
      "0\t0.50000002\tb'belov grandmoth'\n",
      "Твердження: Sr. Financial Analyst - Expedia, Inc.: (#Bellevue, WA) http://t.co/ktknMhvwCI #Finance #ExpediaJobs #Job #Jobs #Hiring\n",
      "Оброблене твердження: ['sr', 'financi', 'analyst', 'expedia', 'inc', 'bellevu', 'wa', 'financ', 'expediajob', 'job', 'job', 'hire']\n",
      "0\t0.50648681\tb'sr financi analyst expedia inc bellevu wa financ expediajob job job hire'\n"
     ]
    }
   ],
   "source": [
    "# Some error analysis done for you\n",
    "for x,y in zip(test_x,test_y):\n",
    "    y_hat = predict_tweet(x, freqs, theta)\n",
    "\n",
    "    if np.abs(y - (y_hat > 0.5)) > 0:\n",
    "        print('Твердження:', x)\n",
    "        print('Оброблене твердження:', process_tweet(x))\n",
    "        print('%d\\t%0.8f\\t%s' % (y, y_hat, ' '.join(process_tweet(x)).encode('ascii', 'ignore')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Прогнозування власного твердження"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hate', 'footbal', 'team', 'play', 'game', 'field']\n",
      "[[0.49534019]]\n",
      "Negative sentiment\n"
     ]
    }
   ],
   "source": [
    "# Feel free to change the tweet below\n",
    "my_tweet = 'I hate when our football team plays on own game field!'\n",
    "print(process_tweet(my_tweet))\n",
    "y_hat = predict_tweet(my_tweet, freqs, theta)\n",
    "print(y_hat)\n",
    "if y_hat > 0.5:\n",
    "    print('Positive sentiment')\n",
    "else: \n",
    "    print('Negative sentiment')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
