{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Аналіз тонування тексту\n",
    "Для аналізу тонування тексту певного твердження із соціальної мережі Twitter буде використовуватися логістична регресія. Дано твердження, потрібно вирішити чи має воно позитивне тонування чи негативне. Для цього потрібно зробити наступні кроки:  \n",
    "* Визначити ознаки з деякого тексту для логістичної регресії\n",
    "* Створити алгоритм логістичної регресії\n",
    "* Застосувати логістичну регресію для задачі обробки натуральної мови\n",
    "* Протестувати логістичну регресію\n",
    "* Проаналізувати точність логістичної регресії"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Імпорт функцій і даних\n",
    "\n",
    "### Зчитування набору даних\n",
    "\n",
    "\n",
    "Оригінальна документація набору вхідних приведена у [документація для набору даних із мережі Twitter](http://www.nltk.org/howto/twitter.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package twitter_samples to\n",
      "[nltk_data]     C:\\Users\\Андрей\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package twitter_samples is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Андрей\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run this cell to import nltk\n",
    "import nltk\n",
    "from os import getcwd\n",
    "\n",
    "nltk.download('twitter_samples')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Імпорт функцій\n",
    "\n",
    "#### NaturalLanguageProcessing-модуль:\n",
    "* process_tweet: повертає попередньо оброблене твердження, а саме видаляє усі посилання, хештег-символи, токенізує рядок, приводить слова до нижнього регістру, видаляє стоп слова та пунктуацію, приводить слова до кореня.\n",
    "* build_freqs: повертає словник, що має (слово, тонація) в якості ключа і частоту використання слова до відповідної тональності в якості значення.\n",
    "\n",
    "\n",
    "#### MachineLearning-модуль\n",
    "* sigmoid: функція сигмоїди. Вихідним значенням є результат сигмоїди.\n",
    "* gradientDescent: функція, що представляє собою алгоритм градієнтного спуску. У результаті виконання повертає значення функції вартості J та оновлений вектор вагових коефіцієнтів theta.\n",
    "* extract_features: функція вилучення ознак у твердженні, що приймає одне твердження та словник частотності слів.\n",
    "* predict_tweet: функція для прогнозування чи твердження позитивне чи негативне. Повертає прогнозоване значення за допомогою налаштованої моделі класифікації.\n",
    "* test_logistic_regression: функція для перевірки точності побудованої моделі. Повертає значення точності прогнозування міток для тестового набору даних"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "filePath = f\"{getcwd()}/../tmp2/\"\n",
    "nltk.data.path.append(filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import twitter_samples \n",
    "\n",
    "from NaturalLanguageProcessing import process_tweet, build_freqs\n",
    "from MachineLearning import sigmoid, gradientDescent, extract_features, predict_tweet, test_logistic_regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Поділ на тренуючий та тестовий набори даних\n",
    "Набір даних `twitter_samples` має підмножину з 5000 позитивних тверджень і 5000 негативних. Повна кількість записів у наборі даних складає 10000 тверджень.\n",
    "\n",
    "Розбиття даних на тренуючий та тестовий набори відбуватися у наступних співвідношеннях: \n",
    "* 20% буде у тестовому наборі;\n",
    "* 80% у тренуючому наборі."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "all_negative_tweets = twitter_samples.strings('negative_tweets.json')\n",
    "\n",
    "train_pos = all_positive_tweets[:4000]\n",
    "train_neg = all_negative_tweets[:4000]\n",
    "\n",
    "test_pos = all_positive_tweets[4000:]\n",
    "test_neg = all_negative_tweets[4000:]\n",
    "\n",
    "train_x = train_pos + train_neg \n",
    "test_x = test_pos + test_neg\n",
    "\n",
    "train_y = np.append(np.ones((len(train_pos), 1)), np.zeros((len(train_neg), 1)), axis=0)\n",
    "test_y = np.append(np.ones((len(test_pos), 1)), np.zeros((len(test_neg), 1)), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вивід кількості даних у тренуючому та тестовому наборах відповідно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Розмірність тренуючого набору даних = (8000, 1)\n",
      "Розмірність тестуючого набору даних = (2000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Розмірність тренуючого набору даних = \" + str(train_y.shape))\n",
    "print(\"Розмірність тестуючого набору даних = \" + str(test_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Приклад даних"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Твердження з позитивним змістом: \n",
      "@VJAdeel \n",
      "Weltum he teh dety :p Huh =D\n",
      "\n",
      "Твердження з негативним змістом: \n",
      "WHY MUST THE VIDEO STOP THO :(\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "print('Твердження з позитивним змістом: \\n' + train_pos[random.randint(0, 4000)])\n",
    "print('\\nТвердження з негативним змістом: \\n' + train_neg[random.randint(0, 4000)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Вилучення ознак\n",
    "\n",
    "Для кожного твердження у наборі даних потрібно дістати дві ознаки, а саме:\n",
    "* Перша ознака - це кількість позитивних слів у тверджені.\n",
    "* Друга ознака - це кількість негативних слів у тверджені. \n",
    "\n",
    "\n",
    "### Етап попередньої обробки даних\n",
    "Етап попередньої обробки даних відбувається разом з етапом вилучення ознак.\n",
    "Функція для попередньої обробки даних `process_tweet`, що використовується у функції вилучення ознак `extract_features` містить усі етапи обробки даних:\n",
    "* Токенізація рядка.\n",
    "* Приведення тексту до нижнього регістру.\n",
    "* Видалення стоп слів і пунктуації.\n",
    "* Приведення слів до їх кореня.\n",
    "\n",
    "\n",
    "### Приклад використання функції `process_tweet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Твердження у соціальній мережі твітер: \n",
      " @chingyapp hmmm, i think night better :)\n",
      "\n",
      "Оброблений вид цього твердження: \n",
      " ['hmmm', 'think', 'night', 'better', ':)']\n"
     ]
    }
   ],
   "source": [
    "process_tweet_example = train_x[random.randint(0,8000)]\n",
    "print('Твердження у соціальній мережі твітер: \\n', process_tweet_example)\n",
    "print('\\nОброблений вид цього твердження: \\n', process_tweet(process_tweet_example))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вилучення ознак\n",
    "#### Створення словника частотності\n",
    "Створення словника частот наявних слів відбувається за допомогою імпортованої функції `build_freqs` .  \n",
    "Ключом у такому словнику є пара (слово, мітка), наприклад (\"дослідження\", 1) або (\"дослідження\", 0). Значення, що зберігається для кожного ключа є кількість разів, коли слово \"дослідження\" асоціювалось з позитивної міткою, або з негативною міткою відповідно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тип змінної, що представляє словник: <class 'dict'>\n",
      "Кількість слів у словнику: 11436\n"
     ]
    }
   ],
   "source": [
    "freqs = build_freqs(train_x, train_y)\n",
    "print(\"Тип змінної, що представляє словник: \" + str(type(freqs)))\n",
    "print(\"Кількість слів у словнику: \" + str(len(freqs.keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Підрахунок частот\n",
    "Для кожного слова у словника підраховується кількість вживання слова як у твердженнях з позитивною тональністю, так і з негативною. Таким чином, ми отримуємо дві характеристики."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect the features 'x' and stack them into a matrix 'X'\n",
    "X = np.zeros((len(train_x), 3))\n",
    "for i in range(len(train_x)):\n",
    "    X[i, :]= extract_features(train_x[i], freqs)\n",
    "    \n",
    "\n",
    "# training labels corresponding to X\n",
    "Y = train_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Приклад використання функції `extract_features`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Приклад для твердження, що має слова наявні у словнику:\n",
      "\n",
      "Твердження: @s0ulfl0wr When's your birthday ? :(\n",
      "[[1.000e+00 5.400e+01 3.692e+03]]\n",
      "\n",
      "\n",
      "Приклад для твердження, яке не має слів наявних у словнику:\n",
      "\n",
      "[[1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print('Приклад для твердження, що має слова наявні у словнику:\\n')\n",
    "extract_features_example = train_x[random.randint(0,8000)]\n",
    "print('Твердження: ' + str(extract_features_example))\n",
    "tmp1 = extract_features(extract_features_example, freqs)\n",
    "print(tmp1)\n",
    "\n",
    "print('\\n\\nПриклад для твердження, яке не має слів наявних у словнику:\\n')\n",
    "tmp1 = extract_features('Baaang HEEEY', freqs)\n",
    "print(tmp1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Побудова моделі передбачення \n",
    "\n",
    "\n",
    "### 4.1: Сигмоїда\n",
    "Для класифікації тексту використовуватиметься логістична регресія, яка складається з сигмоїдної функції. \n",
    "* Сигмоїдна функція визначена як: \n",
    "\n",
    "$$ h(z) = \\frac{1}{1+\\exp^{-z}} \\tag{1}$$\n",
    "\n",
    "Вона ставить у відповідність вхідній змінній z значення в інтервалі між 0 і 1, і таким чином може бути використана як функція вірогідності. \n",
    "\n",
    "<div style=\"width:image width px; font-size:100%; text-align:center;\"><img src='./images/sigmoid_plot.jpg' alt=\"alternate text\" width=\"width\" height=\"height\" style=\"width:300px;height:200px;\" /> Figure 1 </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Логістична регресія: регресія і сигмоїда\n",
    "\n",
    "Логістична регресія бере звичайну лінійну регресія і застосовує сигмоїду до вихідного значення лінійної регресії.\n",
    "\n",
    "Регресія:\n",
    "$$z = \\theta_0 x_0 + \\theta_1 x_1 + \\theta_2 x_2 + ... \\theta_N x_N$$\n",
    "Тут  $\\theta$ значення -  \"вагові коефіцієнти\".\n",
    "\n",
    "Логістична регресія\n",
    "$$ h(z) = \\frac{1}{1+\\exp^{-z}}$$\n",
    "$$z = \\theta_0 x_0 + \\theta_1 x_1 + \\theta_2 x_2 + ... \\theta_N x_N$$\n",
    "Тут змінна z за визначенням є 'логітом'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Частина 4.3: Функція вартості і градієнт\n",
    "Функція вартості, що використовується для логістичної регресії розраховується як середнє арифметичне log-функцій для записів із навчального набору даних:\n",
    "\n",
    "$$J(\\theta) = -\\frac{1}{m} \\sum_{i=1}^m y^{(i)}\\log (h(z(\\theta)^{(i)})) + (1-y^{(i)})\\log (1-h(z(\\theta)^{(i)}))\\tag{5} $$\n",
    "* $m$ - кількість записів із навчального набору даних (кількість навчальних записів)\n",
    "* $y^{(i)}$ -  актуальна мітка для навчального запису 'i'.\n",
    "* $h(z^{(i)})$ - прогнозована мітка для навчального запису 'i'.\n",
    "\n",
    "\n",
    "Функція втрат для одного навчального запису:\n",
    "$$ Loss = -1 \\times \\left( y^{(i)}\\log (h(z(\\theta)^{(i)})) + (1-y^{(i)})\\log (1-h(z(\\theta)^{(i)})) \\right)$$\n",
    "\n",
    "* Усі $h$ значення попадають у діапазон \\[0, 1\\], таким чином logs-функції будуть негативними. Це є причина чому мінусовий коефіцієнт був застосований до суми двох термів.\n",
    "\n",
    "* Коли модель прогнозує одиницю ($h(z(\\theta)) = 1$) і мітка 'y' також дорівнює одиниці, величина втрати для цього навчального запису дорівнює нулю. \n",
    "* Схожим чином, коли модель прогнозує нуль ($h(z(\\theta)) = 0$) і актуальна мітка дорівнює нулю, величина втрат для цього навчального запису дорівнює нулю. \n",
    "* Але коли модель прогнозування близька до одиниці ($h(z(\\theta)) = 0.9999$), а актуальна мітка дорівнює нулю, другий терм приймає велике негативне значення, яке потім помножено на мінусовий коефіцієнт -1 для конвертації у позитивне значення величини втрати. $-1 \\times (1 - 0) \\times log(1 - 0.9999) \\approx 9.2$ Чим ближче модель прогнозує значення до 1, тим більша величина втрат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.210340371976294"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-1 * (1 - 0) * np.log(1 - 0.9999) # loss is about 9.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Так само, якщо модель прогнозує значення близьке до нуля ($h(z) = 0.0001$) але актуальна мітка дорівнює одиниці, перший терм у функції втрат приймає велике значення: $-1 \\times log(0.0001) \\approx 9.2$.  Чим ближче модель прогнозує значення до нуля, тим більша величина втрат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.210340371976182"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-1 * np.log(0.0001) # loss is about 9.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Оновлення вагових коефіцієнтів\n",
    "\n",
    "\n",
    "Щоб оновити вектор вагових коефіцієнтів $\\theta$, потрібно застосувати алгоритм градієнтного спуску, щоб ітеративно покращувати прогнозування моделі. \n",
    "\n",
    "Градієнт функції вартості $J$ у відношенні до одного з вагових коефіцієнтів $\\theta_j$ матиме вигляд:\n",
    "\n",
    "$$\\nabla_{\\theta_j}J(\\theta) = \\frac{1}{m} \\sum_{i=1}^m(h^{(i)}-y^{(i)})x^{(i)}_j \\tag{5}$$\n",
    "* 'i' - це індекс поміж усіх 'm' навчальних записів.\n",
    "* 'j' - це індекс вагового коефіцієнта $\\theta_j$, таким чином $x^{(i)}_j$ - це ознака, що асоційована з ваговим коефіцієнтом $\\theta_j$\n",
    "\n",
    "* Щоб оновити ваговий коефіцієнт $\\theta_j$, ми налаштовуємо його віднявши частку градієнта за допомогою коефіцієнта $\\alpha$:\n",
    "$$\\theta_j = \\theta_j - \\alpha \\times \\nabla_{\\theta_j}J(\\theta) $$\n",
    "* Темп навчання (англ. \"learning rate\") $\\alpha$ - це значення, яке ми вибираємо для контроля наскільки великим буде значення одного оновлення.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Функція алгоритму градієнтного спуску\n",
    "* Кількість ітерацій \"num_iters\" - це кількість разів, яка буде використана для навчального набору даних\n",
    "* Для кожної ітерації буде обчислена функція вартості використовуючи усі навчальні записи (всього 'm' навчальних записів), і усі ознаки.\n",
    "* Замість оновлення одного вагового коефіцієнта за одну одиницю часу, ми оновлюємо усі вагові коефіцієнти у векторі:\n",
    "$$\\mathbf{\\theta} = \\begin{pmatrix}\n",
    "\\theta_0\n",
    "\\\\\n",
    "\\theta_1\n",
    "\\\\ \n",
    "\\theta_2 \n",
    "\\\\ \n",
    "\\vdots\n",
    "\\\\ \n",
    "\\theta_n\n",
    "\\end{pmatrix}$$\n",
    "* $\\mathbf{\\theta}$ має розмірність (n+1, 1), де 'n' - кількість ознак, а ще один елемент є вільним коефіцієнтом $\\theta_0$ . Важливо зазначити, що відповідна ознака $\\mathbf{x_0}$  має значення 1).\n",
    "* 'логіти', 'z', обчислені за допомогою множення матриці ознак 'x' на вектор вагових коефіцієнтів 'theta'.  $z = \\mathbf{x}\\mathbf{\\theta}$\n",
    "    * $\\mathbf{x}$ має розмірність (m, n+1) \n",
    "    * $\\mathbf{\\theta}$: має розмірність (n+1, 1)\n",
    "    * $\\mathbf{z}$: має розмірність (m, 1)\n",
    "* Прознозування 'h', обчислено за шляхом застосуванням сигмоїди до кожного елемента у 'z': $h(z) = sigmoid(z)$, і має розмірність (m,1).\n",
    "* Функція вартості $J$ обчислена шляхом крапкового добутку векторів 'y' та 'log(h)'. Оскільки обидві змінні 'y' та 'h' є векторами розмірністю (m,1), треба транспонувати вектор, щоб множення вектора рядка матриці з колонкою вектора було крапковим добутком.\n",
    "$$J = \\frac{-1}{m} \\times \\left(\\mathbf{y}^T \\cdot log(\\mathbf{h}) + \\mathbf{(1-y)}^T \\cdot log(\\mathbf{1-h}) \\right)$$\n",
    "* Оновлення theta також векторізоване.  Оскільки розмірності  $\\mathbf{x}$  (m, n+1), а обі змінні $\\mathbf{h}$ і $\\mathbf{y}$ (m, 1), потрібно транспонувати  $\\mathbf{x}$ , щоб застосувати матричне множення, яке дасть  (n+1, 1) відповідь, що нам і потрібно:\n",
    "$$\\mathbf{\\theta} = \\mathbf{\\theta} - \\frac{\\alpha}{m} \\times \\left( \\mathbf{x}^T \\cdot \\left( \\mathbf{h-y} \\right) \\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Щоб натренувати модель потрібно Визвати функцію градієнтного спуску `gradientDescent`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Функція вартості після тренування = 0.22522315.\n",
      "Результуючий вектор вагових коефіцієнтів: [6e-08, 0.00053818, -0.0005583]\n"
     ]
    }
   ],
   "source": [
    "J, theta = gradientDescent(X, Y, np.zeros((3, 1)), 1e-9, 1500)\n",
    "print(f\"Функція вартості після тренування = {J:.8f}.\")\n",
    "print(f\"Результуючий вектор вагових коефіцієнтів: {[round(t, 8) for t in np.squeeze(theta)]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Оцінка моделі на тестовому наборі даних\n",
    "\n",
    "Після тренування моделі, перевіримо як наша модель може бути застосована на дійсних даних з якими модель ще не працювала.\n",
    "Для цього викоростаємо функцію `predict_tweet`, яка із заданною побудованною моделю спрогнозує чи твердження позитивне або негативне\n",
    "\n",
    "### Приклад використання функції `predict_tweet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am happy -> 0.519275\n",
      "I am bad -> 0.494347\n",
      "this movie should have been great. -> 0.515979\n",
      "great -> 0.516065\n",
      "great great -> 0.532096\n",
      "great great great -> 0.548062\n",
      "great great great great -> 0.563929\n",
      "I am learning :) -> 0.831103\n",
      ":) -> 0.830885\n",
      ":( -> 0.113930\n"
     ]
    }
   ],
   "source": [
    "example_predict_tweet = ['I am happy',\n",
    "                         'I am bad',\n",
    "                         'this movie should have been great.',\n",
    "                         'great',\n",
    "                         'great great',\n",
    "                         'great great great',\n",
    "                         'great great great great',\n",
    "                         'I am learning :)',\n",
    "                        ':)',\n",
    "                        ':(']\n",
    "\n",
    "for tweet in example_predict_tweet:\n",
    "    print( '%s -> %f' % (tweet, predict_tweet(tweet, freqs, theta)))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оцінка моделі на тестовому наборі даних\n",
    "\n",
    "Дано тестовий набір даних і вагові коефіцієнти побудованої моделі. Обчислимо точність побудованої логістичної регресійної моделі за допомогою функції `test_logistic_regression` , яка містить функцію для прогнозування кожного твердження у наборі даних - `predict_tweet`.\n",
    "* Якщо прогнозування більше > 0.5, то встановити класифікацію моделі рівній 1, інакше встановити класифікацію моделі рівній 0.\n",
    "* Прогнозування точне коли пронозована мітка відповідає актуальній. Потрібно підсумувати кількість правильних відповідностей і поділити на загальну кількість міток у тестовому наборі даних.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точність логістичної регресійної моделі = 0.9950\n"
     ]
    }
   ],
   "source": [
    "tmp_accuracy = test_logistic_regression(test_x, test_y, freqs, theta)\n",
    "print(f\"Точність логістичної регресійної моделі = {tmp_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Аналіз помилок\n",
    "\n",
    "У цій частині буде видно деякі твердження, що були невірно класифіковані."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Твердження: @MarkBreech Not sure it would be good thing 4 my bottom daring 2 say 2 Miss B but Im gonna be so stubborn on mouth soaping ! #NotHavingit :p\n",
      "Оброблене твердження: ['sure', 'would', 'good', 'thing', '4', 'bottom', 'dare', '2', 'say', '2', 'miss', 'b', 'im', 'gonna', 'stubborn', 'mouth', 'soap', 'nothavingit', ':p']\n",
      "1\t0.48901497\tb'sure would good thing 4 bottom dare 2 say 2 miss b im gonna stubborn mouth soap nothavingit :p'\n",
      "Твердження: I'm playing Brain Dots : ) #BrainDots\n",
      "http://t.co/UGQzOx0huu\n",
      "Оброблене твердження: [\"i'm\", 'play', 'brain', 'dot', 'braindot']\n",
      "1\t0.48418949\tb\"i'm play brain dot braindot\"\n",
      "Твердження: I'm playing Brain Dots : ) #BrainDots http://t.co/aOKldo3GMj http://t.co/xWCM9qyRG5\n",
      "Оброблене твердження: [\"i'm\", 'play', 'brain', 'dot', 'braindot']\n",
      "1\t0.48418949\tb\"i'm play brain dot braindot\"\n",
      "Твердження: I'm playing Brain Dots : ) #BrainDots http://t.co/R2JBO8iNww http://t.co/ow5BBwdEMY\n",
      "Оброблене твердження: [\"i'm\", 'play', 'brain', 'dot', 'braindot']\n",
      "1\t0.48418949\tb\"i'm play brain dot braindot\"\n",
      "Твердження: off to the park to get some sunlight : )\n",
      "Оброблене твердження: ['park', 'get', 'sunlight']\n",
      "1\t0.49636374\tb'park get sunlight'\n",
      "Твердження: @msarosh Uff Itna Miss karhy thy ap :p\n",
      "Оброблене твердження: ['uff', 'itna', 'miss', 'karhi', 'thi', 'ap', ':p']\n",
      "1\t0.48237069\tb'uff itna miss karhi thi ap :p'\n",
      "Твердження: @phenomyoutube u probs had more fun with david than me : (\n",
      "Оброблене твердження: ['u', 'prob', 'fun', 'david']\n",
      "0\t0.50988239\tb'u prob fun david'\n",
      "Твердження: pats jay : (\n",
      "Оброблене твердження: ['pat', 'jay']\n",
      "0\t0.50040365\tb'pat jay'\n",
      "Твердження: my beloved grandmother : ( https://t.co/wt4oXq5xCf\n",
      "Оброблене твердження: ['belov', 'grandmoth']\n",
      "0\t0.50000002\tb'belov grandmoth'\n",
      "Твердження: Sr. Financial Analyst - Expedia, Inc.: (#Bellevue, WA) http://t.co/ktknMhvwCI #Finance #ExpediaJobs #Job #Jobs #Hiring\n",
      "Оброблене твердження: ['sr', 'financi', 'analyst', 'expedia', 'inc', 'bellevu', 'wa', 'financ', 'expediajob', 'job', 'job', 'hire']\n",
      "0\t0.50648681\tb'sr financi analyst expedia inc bellevu wa financ expediajob job job hire'\n"
     ]
    }
   ],
   "source": [
    "# Some error analysis done for you\n",
    "for x,y in zip(test_x,test_y):\n",
    "    y_hat = predict_tweet(x, freqs, theta)\n",
    "\n",
    "    if np.abs(y - (y_hat > 0.5)) > 0:\n",
    "        print('Твердження:', x)\n",
    "        print('Оброблене твердження:', process_tweet(x))\n",
    "        print('%d\\t%0.8f\\t%s' % (y, y_hat, ' '.join(process_tweet(x)).encode('ascii', 'ignore')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Later in this specialization, we will see how we can use deeplearning to improve the prediction performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Прогнозування для свого власного твердження"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hate', 'footbal', 'team', 'play', 'game', 'field']\n",
      "[[0.49534019]]\n",
      "Negative sentiment\n"
     ]
    }
   ],
   "source": [
    "# Feel free to change the tweet below\n",
    "my_tweet = 'I hate when our football team plays on own game field!'\n",
    "print(process_tweet(my_tweet))\n",
    "y_hat = predict_tweet(my_tweet, freqs, theta)\n",
    "print(y_hat)\n",
    "if y_hat > 0.5:\n",
    "    print('Positive sentiment')\n",
    "else: \n",
    "    print('Negative sentiment')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
